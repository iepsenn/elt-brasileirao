{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential()\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.20))\n",
    "# model.add(Dense(2048,activation='relu',input_dim=train.shape[1],kernel_initializer='uniform'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(2048,activation='tanh'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(1048,activation='tanh'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.25))\n",
    "# #model.add(Dense(1024,kernel_initializer='uniform',activation='tanh'))\n",
    "# #model.add(Dropout(0.5))\n",
    "# model.add(Dense(target.shape[1],activation='sigmoid'))\n",
    "\n",
    "\n",
    "# sgd=SGD(lr=0.01,momentum=0.9)\n",
    "# model.compile(optimizer=sgd,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "# model.fit(train.values,target.values,batch_size=60,epochs=100,verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/serieA_matches.csv')\n",
    "df_all_matches = pd.read_csv('data/2020_all_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.17 ms, sys: 11 µs, total: 4.18 ms\n",
      "Wall time: 4.71 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "home_teams = df_all_matches[['Home', 'Venue']].drop_duplicates().values\n",
    "team_stadium = {}\n",
    "for data in home_teams:\n",
    "     team_stadium[data[0]] = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.6 ms, sys: 0 ns, total: 26.6 ms\n",
      "Wall time: 182 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "team_dict = {}\n",
    "for idx, team in enumerate(df['team'].unique()):\n",
    "    team_dict[team] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_home'] = team_stadium[df['team'].iloc[0]]\n",
    "df['is_home'] = df['stadium'] == df['is_home']\n",
    "df['is_home'] = df['is_home'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "team       object\n",
       "result     object\n",
       "stadium    object\n",
       "state      object\n",
       "UF         object\n",
       "date       object\n",
       "time       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_types = df.dtypes\n",
    "cols_types[cols_types == object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fouls</th>\n",
       "      <th>corners</th>\n",
       "      <th>crosses</th>\n",
       "      <th>touches</th>\n",
       "      <th>tackles</th>\n",
       "      <th>interceptions</th>\n",
       "      <th>aerials_won</th>\n",
       "      <th>clearances</th>\n",
       "      <th>offsides</th>\n",
       "      <th>goal_kicks</th>\n",
       "      <th>...</th>\n",
       "      <th>fouls_drawn_mean_attack</th>\n",
       "      <th>offsides_mean_attack</th>\n",
       "      <th>crosses_mean_attack</th>\n",
       "      <th>tackles_on_mean_attack</th>\n",
       "      <th>interceptions_mean_attack</th>\n",
       "      <th>own_goals_mean_attack</th>\n",
       "      <th>penalty_kicks_won_mean_attack</th>\n",
       "      <th>penalty_kicks_conceded_mean_attack</th>\n",
       "      <th>year</th>\n",
       "      <th>is_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fouls  corners  crosses  touches  tackles  interceptions  aerials_won  \\\n",
       "0   23.0      3.0     11.0    436.0     12.0            5.0          7.0   \n",
       "1   23.0      3.0     11.0    436.0     12.0            5.0          7.0   \n",
       "\n",
       "   clearances  offsides  goal_kicks  ...  fouls_drawn_mean_attack  \\\n",
       "0        18.0       2.0         4.0  ...                      0.0   \n",
       "1        18.0       2.0         4.0  ...                      0.0   \n",
       "\n",
       "   offsides_mean_attack  crosses_mean_attack tackles_on_mean_attack  \\\n",
       "0                   2.0                  1.0                    0.0   \n",
       "1                   2.0                  1.0                    0.0   \n",
       "\n",
       "   interceptions_mean_attack own_goals_mean_attack  \\\n",
       "0                        1.0                   0.0   \n",
       "1                        1.0                   0.0   \n",
       "\n",
       "  penalty_kicks_won_mean_attack penalty_kicks_conceded_mean_attack  year  \\\n",
       "0                           NaN                                NaN  2019   \n",
       "1                           NaN                                NaN  2019   \n",
       "\n",
       "   is_home  \n",
       "0        0  \n",
       "1        0  \n",
       "\n",
       "[2 rows x 120 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['date'] = pd.to_datetime(df['date'])\n",
    "df['time'] = df['time'].apply(lambda time: time.split(':')[0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['year'] = df['date'].dt.year\n",
    "# df['month'] = df['date'].dt.month\n",
    "# df['quarter'] = df['date'].dt.quarter\n",
    "# df['day'] = df['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove = [\n",
    "    'result',\n",
    "    \"date\",\n",
    "#     'team',\n",
    "    \"stadium\",\n",
    "    \"state\",\n",
    "    \"UF\",\n",
    "#     \"match_id\"\n",
    "]\n",
    "y_col = 'score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=cols_to_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in df.columns if col not in cols_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_home_teams = pd.DataFrame()\n",
    "df_adversary_teams = pd.DataFrame()\n",
    "\n",
    "df_teams = pd.DataFrame()\n",
    "for team in df['team'].unique():\n",
    "    cols_to_drop = ['is_home', 'team', 'score']\n",
    "\n",
    "    df_team = df[df['team'] == team].copy().reset_index(drop=True)\n",
    "    df_others_teams = df[\n",
    "        (df['team'] != team) &\n",
    "        (df['match_id'].isin(df_team['match_id'].tolist()))\n",
    "    ].copy().reset_index(drop=True)\n",
    "    \n",
    "    columns = [col for col in df_team if col not in cols_to_drop]\n",
    "    df_team.loc[df_team.index >= 3, columns] = (\n",
    "        df_team[columns]\n",
    "        .shift(1)\n",
    "        .rolling(3)\n",
    "        .mean()\n",
    "        .iloc[3:]\n",
    "    )\n",
    "\n",
    "    df_others_teams.loc[df_others_teams.index >= 3, columns] = (\n",
    "        df_team[columns]\n",
    "        .shift(1)\n",
    "        .rolling(3)\n",
    "        .mean()\n",
    "        .iloc[3:]\n",
    "    )\n",
    "\n",
    "    df_others_teams.drop(columns=cols_to_drop, inplace=True)\n",
    "    df_others_teams.columns = [\n",
    "        col + '_adversary' if col != 'match_id' else col for col in df_others_teams.columns\n",
    "    ]\n",
    "    \n",
    "    for col in [column for column in df_others_teams.columns if column.endswith('adversary')]:\n",
    "        df_team[col] = df_others_teams[col]\n",
    "    \n",
    "#     df_teams = df_teams.append(\n",
    "#         df_team.merge(df_others_teams, on='match_id')\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_teams = df_home_teams.append(\n",
    "#     df_adversary_teams.merge(df_others_teams, on='match_id')\n",
    "# )\n",
    "\n",
    "df_teams = df_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams = df_teams[~df_teams['team'].isna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_teams['team'] = df_teams['team'].apply(lambda team: team_dict[team])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams['score'].fillna(-1, inplace=True)\n",
    "df_teams = df_teams[df_teams['score'] != -1]\n",
    "df_teams['score'] = df_teams['score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_teams.drop(columns=['score'])\n",
    "Y = df_teams['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score\n",
    "# result\n",
    "\n",
    "# df.drop(columns=['result'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=cols_to_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBClassifier()\n",
    "\n",
    "# rfe = RFE(model, 25)\n",
    "# fit = rfe.fit(X, Y)\n",
    "# print(\"Num Features: %d\" % fit.n_features_)\n",
    "# print(\"Selected Features: %s\" % fit.support_)\n",
    "# print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import f_classif\n",
    "\n",
    "# test = SelectKBest(score_func=f_classif, k=25)\n",
    "# fit = test.fit(X, Y)\n",
    "# # summarize scores\n",
    "# print(fit.scores_)\n",
    "# features = fit.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = np.array(np.array(X.columns.tolist()))[list(fit.support_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    difference = list(np.abs((y_true - y_pred) / y_true))\n",
    "    difference = [diff if diff != np.inf and not pd.isnull(diff) else 0 for diff in difference]\n",
    "    return np.mean(difference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_percentage(y_true, y_pred): \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    return  np.sum(y_pred) / np.sum(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.sort_values(['matchweek', 'team'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # n_cols_list = [5, 15, 25, 35, 45, 50, 63, 72, 84, 90, 100]\n",
    "# # for n_cols in n_cols_list:\n",
    "n_cols = 50\n",
    "\n",
    "# model = XGBRegressor()\n",
    "\n",
    "# rfe = RFE(model, n_cols)\n",
    "# fit = rfe.fit(X, Y)\n",
    "\n",
    "# cols = np.array(np.array(X.columns.tolist()))[list(fit.support_)]\n",
    "# X_new = X[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, Y, test_size=0.1, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# parameters = {\n",
    "#     'eta': [0.05, 0.1, 0.3],\n",
    "#     'max_depth': [5, 6, 9, 12, 20],\n",
    "#     'subsample': [0.7, 0.6, 0.8, 1.0],\n",
    "#     'colsample_bytree': [0.3, 0.6, 0.8, 1.0],\n",
    "#     'min_child_weight': [1, 5, 8, 10],\n",
    "#     'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "#     'n_estimators': [50, 100, 150, 500, 1000]\n",
    "# }\n",
    "\n",
    "# clf = GridSearchCV(model, parameters, n_jobs=1, cv=3)\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# best_parameters = clf.best_params_\n",
    "\n",
    "# model = XGBRegressor(**best_parameters)\n",
    "model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE with 50 columns: 0.60%\n",
      "MAE with 50 columns: 0.01\n",
      "BIAS% with 50 columns: 99.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-75-70d46a524b4a>:5: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  difference = list(np.abs((y_true - y_pred) / y_true))\n",
      "<ipython-input-75-70d46a524b4a>:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  difference = list(np.abs((y_true - y_pred) / y_true))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = list(model.predict(X_test))\n",
    "predictions = list([round(value) for value in y_pred])\n",
    "\n",
    "# evaluate predictions\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "bias_percent = bias_percentage(y_test, predictions)\n",
    "\n",
    "print(\"MAPE with {} columns: {:.2f}%\".format(n_cols, mape * 100.0))\n",
    "print(\"MAE with {} columns: {:.2f}\".format(n_cols, mae))\n",
    "print(\"BIAS% with {} columns: {:.2f}%\".format(n_cols, bias_percent * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_test1 = {\n",
    "#  'max_depth':range(3,10,2),\n",
    "#  'min_child_weight':range(1,6,2)\n",
    "# }\n",
    "# gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "#  min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "#  objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    "#  param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "# gsearch1.fit(train[predictors],train[target])\n",
    "# gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_per_round = df['matchweek'].value_counts().to_frame()\n",
    "last_matchweek = match_per_round[match_per_round > 5].sort_values('matchweek', ascending=False).iloc[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_matches = pd.read_csv('data/2020_all_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_matches['Score'] = next_matches['Score'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_matches = next_matches[next_matches['Score'] == '']\n",
    "next_matches['Wk'] = next_matches['Wk'].fillna('')\n",
    "next_matches = next_matches[next_matches['Wk'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_matches = next_matches[next_matches['Wk'] > last_matchweek]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_match_id = df['match_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(interested_team, other_team, cols):\n",
    "    cols_to_use = [col for col in interested_team.columns if 'adversary' not in col]\n",
    "    \n",
    "    interested_team = interested_team[cols_to_use]\n",
    "    other_team = other_team[cols_to_use]\n",
    "    \n",
    "    other_team.columns = [col + '_adversary' if col not in ['result', 'match_id'] else col for col in interested_team.columns ]\n",
    "    \n",
    "    df = interested_team.merge(other_team, on='match_id')\n",
    "\n",
    "    return df[cols]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodada 15: Vasco da Gama 1 x 2 Flamengo!\n",
      "Rodada 15: Palmeiras 2 x 2 São Paulo!\n",
      "Rodada 15: Atlético Mineiro 1 x 2 Goiás!\n",
      "Rodada 15: Fluminense 1 x 1 Bahia!\n",
      "Rodada 15: Santos 1 x 1 Grêmio!\n",
      "Rodada 15: Ceará 2 x 1 Corinthians!\n",
      "Rodada 15: Internacional 1 x 1 Atl Paranaense!\n",
      "Rodada 11: Flamengo 1 x 2 Goiás!\n"
     ]
    }
   ],
   "source": [
    "for next_match in next_matches.iterrows():\n",
    "    try:\n",
    "        next_match = next_match[1].to_frame().transpose()\n",
    "        team1, team2 = next_match[['Home', 'Away']].iloc[0]\n",
    "        date = pd.to_datetime(next_match['Date'].iloc[0])\n",
    "        if isinstance(next_match['Time'], str):\n",
    "            time = next_match['Time'].iloc[0].split(':')[0]\n",
    "        else:\n",
    "            time = next_match['Time'].iloc[0]\n",
    "            \n",
    "        matchweek = int(next_match['Wk'].iloc[0])\n",
    "\n",
    "        if team1 not in team_dict.keys():\n",
    "            team_dict[team1] = max(team_dict.values()) + 1\n",
    "\n",
    "        if team2 not in team_dict.keys():\n",
    "            team_dict[team2] = max(team_dict.values()) + 1\n",
    "\n",
    "\n",
    "        if matchweek >= last_matchweek + 1:\n",
    "\n",
    "            cols = X_new.columns.tolist()\n",
    "            mean_features_team1 = df[df['team'] == team1].copy()  # [cols]\n",
    "            mean_features_team2 = df[df['team'] == team2].copy()  # [cols]\n",
    "\n",
    "            mean_features_team1['match_id'] = last_match_id + 1\n",
    "            mean_features_team2['match_id'] = last_match_id + 1\n",
    "\n",
    "        #     for col in cols:\n",
    "        #         mean_features_team1[col] = mean_features_team1[col].shift(1).rolling(window=3).mean().copy()\n",
    "        #         mean_features_team2[col] = mean_features_team2[col].shift(1).rolling(window=3).mean().copy()\n",
    "\n",
    "            for col in df.columns:\n",
    "                if df[col].dtype != object and col not in ['score', 'match_id']:\n",
    "                    mean_features_team1[col] = mean_features_team1[col].shift(1).rolling(window=3).mean().copy()\n",
    "                    mean_features_team2[col] = mean_features_team2[col].shift(1).rolling(window=3).mean().copy()\n",
    "\n",
    "            mean_features_team1 = mean_features_team1.iloc[-1:].copy()\n",
    "            mean_features_team2 = mean_features_team2.iloc[-1:].copy()\n",
    "\n",
    "            mean_features_team1['is_home'] = 1\n",
    "            mean_features_team2['is_home'] = 0\n",
    "\n",
    "            mean_features_team1['team'] = team_dict[team1]\n",
    "            mean_features_team2['team'] = team_dict[team2]\n",
    "\n",
    "            dataset_team1 = make_dataset(mean_features_team1, mean_features_team2, cols).round(2)\n",
    "            dataset_team2 = make_dataset(mean_features_team2, mean_features_team1, cols).round(2)\n",
    "\n",
    "            game_prediction = dataset_team1.append(dataset_team2)\n",
    "            prediction = [round(prediction) for prediction in list(model.predict(game_prediction))]\n",
    "            print(f\"Rodada {matchweek}: {team1} {prediction[0]} x {prediction[1]} {team2}!\")\n",
    "            last_match_id += 1\n",
    "            \n",
    "            if matchweek == last_matchweek + 2:\n",
    "                break\n",
    "    except Exception as e:\n",
    "#         print(e)\n",
    "#         print(team1, team2)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
